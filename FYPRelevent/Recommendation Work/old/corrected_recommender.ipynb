{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel, cosine_similarity\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import *\n",
    "\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "from collections import Counter\n",
    "from scipy.sparse.linalg import svds\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HELPING FUNCTIONS\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def lemmatize_stemming(text):\n",
    "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
    "\n",
    "def clean_(sen):\n",
    "    \n",
    "    sen = re.sub(r'[^a-zA-Z\\.\\:\\@0-9_ ]+', '', sen) \n",
    "    sen = sen.lower()\n",
    "    sen = sen.split()\n",
    "#     sen = [lemmatize_stemming(x) for x in sen]\n",
    "    sen = ' '.join(sen)\n",
    "    \n",
    "    return sen\n",
    "\n",
    "\n",
    "\n",
    "def get_events(metadata):\n",
    "#     metadata = pd.read_excel(path)\n",
    "    metadata['Type']=[ x.lower() for x in metadata['Type']]\n",
    "        \n",
    "    eventname= metadata['Event name'].fillna('')\n",
    "    description = (metadata['Event time'] + metadata['Venue']+metadata['Description']+metadata['Source']+metadata['Type']+metadata['City']).fillna('')\n",
    "    description_clean= list(description)\n",
    "\n",
    "    i=0\n",
    "    while(i< len(description)):\n",
    "        description_clean[i]= clean_(description[i])\n",
    "        i+=1\n",
    "    \n",
    "    #improve Description\n",
    "    metadata['Description']=description_clean\n",
    "    return metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#APPLICATION DATA\n",
    "\n",
    "#INPUT FOR THE APPLICATION!\n",
    "def get_prep_data(input_user_id):\n",
    "    data=pd.read_excel('activities.xls')\n",
    "\n",
    "    df_users = pd.DataFrame(columns= ['userId','userName'])\n",
    "    # df_events = get_events(\"activities.xls\")\n",
    "    df_events=get_events(data)\n",
    "\n",
    "    m = pd.read_csv('movies/movies.csv')\n",
    "\n",
    "    df_events['eventId'] = m['movieId']\n",
    "\n",
    "    # df_old_events=df_events.iloc[0:int(df_events.shape[0]*0.8),:]\n",
    "    # df_new_events=df_events.iloc[int(df_events.shape[0]*0.8):,:]\n",
    "\n",
    "    df_rating = pd.read_csv(\"movies/ratings.csv\")\n",
    "    df_rating.rename(columns={'movieId':'eventId'},inplace= True)\n",
    "\n",
    "    userRated=df_rating.loc[df_rating['userId']==input_user_id]\n",
    "\n",
    "    df_old_events=df_events.loc[df_events['eventId'].isin(list(userRated['eventId']))] #Contains user input\n",
    "    df_new_events=df_events.loc[~df_events['eventId'].isin(list(userRated['eventId']))] #Does Not contain user input\n",
    "    return data,df_events,df_rating,df_old_events,df_new_events\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_frequency(df,to_check,col_name,no):\n",
    "#     if int(df.shape[0]>0):\n",
    "#         n=no\n",
    "#         #count\n",
    "#         tmp_count = Counter(list(df[to_check]))\n",
    "#         tmp = pd.DataFrame.from_dict(tmp_count, orient='index')\n",
    "\n",
    "#         #sort\n",
    "#         tmp=tmp.sort_values(0,ascending=False)\n",
    "\n",
    "#         #remove index\n",
    "#         tmp.reset_index(level=0, inplace=True)\n",
    "\n",
    "#         #rename\n",
    "#         tmp=tmp.rename(columns={\"index\":col_name,0:\"Frequency\"})\n",
    "\n",
    "#         #get Top N----\n",
    "#         tmp=tmp.loc[0:n]\n",
    "\n",
    "#         #Perc-Freq\n",
    "#         sumed=sum(tmp[\"Frequency\"])\n",
    "#         tmp[\"Percentage of total\"]=(tmp[\"Frequency\"]/sumed)*100\n",
    "#         return tmp\n",
    "#     else:\n",
    "#         print(\"DataFrame is empty\")\n",
    "        \n",
    "# get_frequency(df_rating,'userId','userId',10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Event name</th>\n",
       "      <th>Event time</th>\n",
       "      <th>Venue</th>\n",
       "      <th>Description</th>\n",
       "      <th>Source</th>\n",
       "      <th>Picture</th>\n",
       "      <th>Type</th>\n",
       "      <th>City</th>\n",
       "      <th>Rated</th>\n",
       "      <th>eventId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Visual Design 101</td>\n",
       "      <td>\\t\\t\\t\\t\\t\\tWed Dec 11 2019 at 03:00 pm to 05:...</td>\n",
       "      <td>National Incubation Center, Plot 24-b, H-9/1,...</td>\n",
       "      <td>wed dec 11 2019 at 03:00 pm to 05:00 pm nation...</td>\n",
       "      <td>National Incubation Center</td>\n",
       "      <td>https://cdn-az.allevents.in/events8/banners/f9...</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>islamabad</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3 Days Trip To Swat Valley  And Malam Jaba</td>\n",
       "      <td>\\t\\t\\t\\t\\t\\tFri Dec 13 2019 at 07:00 am to Sun...</td>\n",
       "      <td>I-8/1, Islamabad, Pakistan</td>\n",
       "      <td>fri dec 13 2019 at 07:00 am to sun dec 15 2019...</td>\n",
       "      <td>North Adventure Club</td>\n",
       "      <td>https://cdn-az.allevents.in/events8/banners/0f...</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>islamabad</td>\n",
       "      <td>False</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>سنی ان سنی’ The Wound Cannot be Heard</td>\n",
       "      <td>\\t\\t\\t\\t\\t\\tFri Dec 13 2019 at 07:00 pm to 09:...</td>\n",
       "      <td>ChaiLogue, Shop number 3, Imperial Square, Kh...</td>\n",
       "      <td>fri dec 13 2019 at 07:00 pm to 09:00 pm chailo...</td>\n",
       "      <td>ChaiLogue</td>\n",
       "      <td>https://cdn-az.allevents.in/events5/banners/31...</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>islamabad</td>\n",
       "      <td>False</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Snow Hike Miranjani Top</td>\n",
       "      <td>\\t\\t\\t\\t\\t\\tSat Dec 14 2019 at 07:00 am to 10:...</td>\n",
       "      <td>Ultra Adventure Club, Bluearea, Islamabad, Pa...</td>\n",
       "      <td>sat dec 14 2019 at 07:00 am to 10:00 pm ultra ...</td>\n",
       "      <td>Ultra Adventure Club</td>\n",
       "      <td>https://cdn-az.allevents.in/events6/banners/bd...</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>islamabad</td>\n",
       "      <td>False</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Certified Self-Discovery &amp; Career Counseling W...</td>\n",
       "      <td>\\t\\t\\t\\t\\t\\tSat Dec 14 2019 at 01:00 pm to 04:...</td>\n",
       "      <td>LaunchPad7, 1st floor Al Rehman Chambers Faza...</td>\n",
       "      <td>sat dec 14 2019 at 01:00 pm to 04:00 pm launch...</td>\n",
       "      <td>Mind Empowerment Consultancy</td>\n",
       "      <td>https://cdn-az.allevents.in/events2/banners/b0...</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>islamabad</td>\n",
       "      <td>False</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>Developers Weekend</td>\n",
       "      <td>\\t\\t\\t\\t\\t\\tSat Feb 22 2020 at 08:00 am to Sun...</td>\n",
       "      <td>COMSATS, Park Road, Chak Shahzad, Islamabad, ...</td>\n",
       "      <td>sat feb 22 2020 at 08:00 am to sun feb 23 2020...</td>\n",
       "      <td>Computer Science Society, CUI, Islamabad</td>\n",
       "      <td>https://cdn-az.allevents.in/events7/banners/5f...</td>\n",
       "      <td>workshops</td>\n",
       "      <td>islamabad</td>\n",
       "      <td>False</td>\n",
       "      <td>237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>Students Package: Karachi to Kaghan Shogran &amp; ...</td>\n",
       "      <td>\\t\\t\\t\\t\\t\\tFri Dec 06 2019 at 08:00 pm to Thu...</td>\n",
       "      <td>Surti Tours and Travels, b-19 noor housing pr...</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://cdn5.allevents.in/images/dates/6-DEC_2...</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>karachi</td>\n",
       "      <td>False</td>\n",
       "      <td>238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>Thinking Films: Parasite (2019)</td>\n",
       "      <td>\\t\\t\\t\\t\\t\\tWed Dec 11 2019 at 07:00 pm to 09:...</td>\n",
       "      <td>T2F, 10-C, Sunset Lane 5, Phase 2 Extension, ...</td>\n",
       "      <td>wed dec 11 2019 at 07:00 pm to 09:30 pm t2f 10...</td>\n",
       "      <td>The Second Floor (T2F)</td>\n",
       "      <td>https://cdn-az.allevents.in/events1/banners/4e...</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>karachi</td>\n",
       "      <td>False</td>\n",
       "      <td>239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>The Extractor's Mania</td>\n",
       "      <td>\\t\\t\\t\\t\\t\\tThu Dec 12 2019 at 11:00 am to 02:...</td>\n",
       "      <td>Dreamworld Club, Gulshan-e-Maymar, Karachi, P...</td>\n",
       "      <td>thu dec 12 2019 at 11:00 am to 02:00 pm dreamw...</td>\n",
       "      <td>Metallurgical Engineers' Society - MES NED</td>\n",
       "      <td>https://cdn-az.allevents.in/events7/banners/0e...</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>karachi</td>\n",
       "      <td>False</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>Snowfall Trip To Quetta &amp; Ziarat</td>\n",
       "      <td>\\t\\t\\t\\t\\t\\tThu Dec 12 2019 at 07:00 pm to Sun...</td>\n",
       "      <td>Safari Pakistan, Office No#513 5th Floor Khay...</td>\n",
       "      <td>thu dec 12 2019 at 07:00 pm to sun dec 15 2019...</td>\n",
       "      <td>Safari Pakistan</td>\n",
       "      <td>https://cdn-az.allevents.in/events5/banners/f5...</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>karachi</td>\n",
       "      <td>False</td>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Event name  \\\n",
       "3                                    Visual Design 101   \n",
       "8           3 Days Trip To Swat Valley  And Malam Jaba   \n",
       "11               سنی ان سنی’ The Wound Cannot be Heard   \n",
       "12                             Snow Hike Miranjani Top   \n",
       "13   Certified Self-Discovery & Career Counseling W...   \n",
       "..                                                 ...   \n",
       "203                                 Developers Weekend   \n",
       "204  Students Package: Karachi to Kaghan Shogran & ...   \n",
       "205                    Thinking Films: Parasite (2019)   \n",
       "206                              The Extractor's Mania   \n",
       "207                   Snowfall Trip To Quetta & Ziarat   \n",
       "\n",
       "                                            Event time  \\\n",
       "3    \\t\\t\\t\\t\\t\\tWed Dec 11 2019 at 03:00 pm to 05:...   \n",
       "8    \\t\\t\\t\\t\\t\\tFri Dec 13 2019 at 07:00 am to Sun...   \n",
       "11   \\t\\t\\t\\t\\t\\tFri Dec 13 2019 at 07:00 pm to 09:...   \n",
       "12   \\t\\t\\t\\t\\t\\tSat Dec 14 2019 at 07:00 am to 10:...   \n",
       "13   \\t\\t\\t\\t\\t\\tSat Dec 14 2019 at 01:00 pm to 04:...   \n",
       "..                                                 ...   \n",
       "203  \\t\\t\\t\\t\\t\\tSat Feb 22 2020 at 08:00 am to Sun...   \n",
       "204  \\t\\t\\t\\t\\t\\tFri Dec 06 2019 at 08:00 pm to Thu...   \n",
       "205  \\t\\t\\t\\t\\t\\tWed Dec 11 2019 at 07:00 pm to 09:...   \n",
       "206  \\t\\t\\t\\t\\t\\tThu Dec 12 2019 at 11:00 am to 02:...   \n",
       "207  \\t\\t\\t\\t\\t\\tThu Dec 12 2019 at 07:00 pm to Sun...   \n",
       "\n",
       "                                                 Venue  \\\n",
       "3     National Incubation Center, Plot 24-b, H-9/1,...   \n",
       "8                          I-8/1, Islamabad, Pakistan    \n",
       "11    ChaiLogue, Shop number 3, Imperial Square, Kh...   \n",
       "12    Ultra Adventure Club, Bluearea, Islamabad, Pa...   \n",
       "13    LaunchPad7, 1st floor Al Rehman Chambers Faza...   \n",
       "..                                                 ...   \n",
       "203   COMSATS, Park Road, Chak Shahzad, Islamabad, ...   \n",
       "204   Surti Tours and Travels, b-19 noor housing pr...   \n",
       "205   T2F, 10-C, Sunset Lane 5, Phase 2 Extension, ...   \n",
       "206   Dreamworld Club, Gulshan-e-Maymar, Karachi, P...   \n",
       "207   Safari Pakistan, Office No#513 5th Floor Khay...   \n",
       "\n",
       "                                           Description  \\\n",
       "3    wed dec 11 2019 at 03:00 pm to 05:00 pm nation...   \n",
       "8    fri dec 13 2019 at 07:00 am to sun dec 15 2019...   \n",
       "11   fri dec 13 2019 at 07:00 pm to 09:00 pm chailo...   \n",
       "12   sat dec 14 2019 at 07:00 am to 10:00 pm ultra ...   \n",
       "13   sat dec 14 2019 at 01:00 pm to 04:00 pm launch...   \n",
       "..                                                 ...   \n",
       "203  sat feb 22 2020 at 08:00 am to sun feb 23 2020...   \n",
       "204                                                      \n",
       "205  wed dec 11 2019 at 07:00 pm to 09:30 pm t2f 10...   \n",
       "206  thu dec 12 2019 at 11:00 am to 02:00 pm dreamw...   \n",
       "207  thu dec 12 2019 at 07:00 pm to sun dec 15 2019...   \n",
       "\n",
       "                                         Source  \\\n",
       "3                    National Incubation Center   \n",
       "8                          North Adventure Club   \n",
       "11                                    ChaiLogue   \n",
       "12                         Ultra Adventure Club   \n",
       "13                 Mind Empowerment Consultancy   \n",
       "..                                          ...   \n",
       "203    Computer Science Society, CUI, Islamabad   \n",
       "204                                         NaN   \n",
       "205                      The Second Floor (T2F)   \n",
       "206  Metallurgical Engineers' Society - MES NED   \n",
       "207                             Safari Pakistan   \n",
       "\n",
       "                                               Picture           Type  \\\n",
       "3    https://cdn-az.allevents.in/events8/banners/f9...  entertainment   \n",
       "8    https://cdn-az.allevents.in/events8/banners/0f...  entertainment   \n",
       "11   https://cdn-az.allevents.in/events5/banners/31...  entertainment   \n",
       "12   https://cdn-az.allevents.in/events6/banners/bd...  entertainment   \n",
       "13   https://cdn-az.allevents.in/events2/banners/b0...  entertainment   \n",
       "..                                                 ...            ...   \n",
       "203  https://cdn-az.allevents.in/events7/banners/5f...      workshops   \n",
       "204  https://cdn5.allevents.in/images/dates/6-DEC_2...  entertainment   \n",
       "205  https://cdn-az.allevents.in/events1/banners/4e...  entertainment   \n",
       "206  https://cdn-az.allevents.in/events7/banners/0e...  entertainment   \n",
       "207  https://cdn-az.allevents.in/events5/banners/f5...  entertainment   \n",
       "\n",
       "          City  Rated  eventId  \n",
       "3    islamabad  False        4  \n",
       "8    islamabad  False        9  \n",
       "11   islamabad  False       12  \n",
       "12   islamabad  False       13  \n",
       "13   islamabad  False       14  \n",
       "..         ...    ...      ...  \n",
       "203  islamabad  False      237  \n",
       "204    karachi  False      238  \n",
       "205    karachi  False      239  \n",
       "206    karachi  False      240  \n",
       "207    karachi  False      241  \n",
       "\n",
       "[100 rows x 10 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new_events=df_new_events.loc[df_new_events['eventId'].isin(list(df_new_events['eventId'].unique())[:100])]\n",
    "df_new_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HELPING FUNCTIONS\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def lemmatize_stemming(text):\n",
    "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
    "\n",
    "def clean_(sen):\n",
    "    \n",
    "    sen = re.sub(r'[^a-zA-Z\\.0-9 ]+', '', sen) \n",
    "    sen = sen.lower()\n",
    "    sen = sen.split()\n",
    "#     sen = [lemmatize_stemming(x) for x in sen]\n",
    "    sen = ' '.join(sen)\n",
    "    \n",
    "    return sen\n",
    "\n",
    "\n",
    "\n",
    "def get_events(path):\n",
    "    metadata = pd.read_excel(path)\n",
    "    metadata['Type']=[ x.lower() for x in metadata['Type']]\n",
    "    \n",
    "    eventname= metadata['Event name'].fillna('')\n",
    "    description = (metadata['Event time'] + metadata['Venue']+metadata['Description']+metadata['Source']+metadata['Type']+metadata['City']).fillna('')\n",
    "    description_clean= list(description)\n",
    "\n",
    "    i=0\n",
    "    while(i< len(description)):\n",
    "        description_clean[i]= clean_(description[i])\n",
    "        i+=1\n",
    "    \n",
    "    #improve Description\n",
    "    metadata['Description']=description_clean\n",
    "    return metadata\n",
    "\n",
    "    \n",
    "\n",
    "def first_element(x):\n",
    "    return x[1]\n",
    "\n",
    "# def get_recommendations(title,headings,mapping_,n=10):\n",
    "#     \"\"\"\n",
    "#     Finds 10 most similar events using the pairwise cosine similarity.\n",
    "#     \"\"\"\n",
    "#     index = (mapping_[title])\n",
    "# #     print(index)\n",
    "    \n",
    "#     simi = list((cosine_similarity[index]))\n",
    "#     indexes = list(range(len(simi)))\n",
    "#     simi= list(zip(indexes,simi))\n",
    "# #     print (sim_scores)\n",
    "    \n",
    "#     simi = sorted(simi, key=first_ele, reverse=True)\n",
    "    \n",
    "# #     ignorning first= itself\n",
    "#     simi=simi[1:]\n",
    "    \n",
    "#     recommendations = metadata.iloc[[i[0] for i in simi]][headings]\n",
    "    \n",
    "#     return recommendations.head(n)\n",
    "\n",
    "\n",
    "def get_recommendations_pop(metadata,title,mapping): #popularity based context\n",
    "    \n",
    "    index = (mapping[title])\n",
    "    simi = list((cosine_similarity[index]))\n",
    "    indexes = list(range(len(simi)))\n",
    "    simi= list(zip(indexes,simi))\n",
    "    simi = sorted(simi, key=first_ele, reverse=True)\n",
    "    \n",
    "    \n",
    "    simi = simi[1:60]\n",
    "    \n",
    "    #calculate vote_count and avergare before doing this\n",
    "    recommendations = metadata.iloc[[i[0] for i in simi]][['title', 'vote_count', 'vote_average']]\n",
    "    \n",
    "    items = metadata.iloc[[i[0] for i in simi]]\n",
    "    \n",
    "    vote_counts = items[items['vote_count'].notnull()]['vote_count'].astype('int')\n",
    "    vote_averages = items[items['vote_average'].notnull()]['vote_average'].astype('float')\n",
    "    \n",
    "    C = vote_averages.mean()\n",
    "    m = vote_counts.quantile(0.60)\n",
    "    \n",
    "    \n",
    "    recommendations = items[(items['vote_count'].notnull()) & (items['vote_average'].notnull()) & (items['vote_count'] >= m)]\n",
    "    \n",
    "    recommendations['vote_count'] = recommendations['vote_count'].astype('int')\n",
    "    recommendations['vote_average'] = recommendations['vote_average'].astype('float')\n",
    "    \n",
    "    recommendations['weighted_rating'] = recommendations.apply(weighted_rating,args=(C,m), axis=1)\n",
    "    recommendations = recommendations.sort_values('weighted_rating', ascending=False)\n",
    "#     print (recommendations.head(2))\n",
    "    recommendations=recommendations[['title', 'vote_average']]\n",
    "    recommendations=recommendations.head(10)\n",
    "    return recommendations\n",
    "\n",
    "\n",
    "def weighted_rating(x,C,m):\n",
    "    v = x['vote_count']\n",
    "    R = x['vote_average']\n",
    "    return (v/(v+m) * R) + (m/(m+v) * C)\n",
    "\n",
    "\n",
    "\n",
    "# def recommend_eventss(userID, preds_matrix , items_matrix, rating_matrix, n=10):\n",
    "    \n",
    "    \n",
    "#     user_predictions = preds_matrix.loc[userID]\n",
    "#     print(user)\n",
    "    \n",
    "    \n",
    "# #     user_rating = rating_matrix.loc[userID]\n",
    "    \n",
    "# #     ratings = user_rating.merge(items_matrix, how = 'left', left_on = 'itemId', right_on = 'ItemID')\n",
    "# #     ratings=ratings.sort_values('rating', ascending = False)\n",
    "    \n",
    "# #     items_matrix=items_matrix.dropna()\n",
    "\n",
    "# #     recommendations = items_matrix.merge(pd.DataFrame(user_predictions), how = 'left',left_on = 'ItemID',right_on = 'itemId')\n",
    "   \n",
    "# #     recommendations=recommendations.drop(columns=['Genres'])\n",
    "# #     recommendations=recommendations.sort_values(userID - 1, ascending = False)\n",
    "# #     recommendations=recommendations.rename(columns = {userID - 1: 'Predictions'})\n",
    "                    \n",
    "\n",
    "#     return recommendations.head(n)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inputs to below function: input_user_id,df_rating,df_events,n= 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# n=6\n",
    "input_user_id=414\n",
    "def get_similar_users(input_user_id,df_rating,df_events,n= 6):\n",
    "    new_ratings = pd.merge(df_rating,df_events[['Event name','eventId']],left_on='eventId',right_on='eventId')\n",
    "#     new_ratings = pd.merge(df_events[['Event name','eventId']],df_rating,left_on='eventId',right_on='eventId')\n",
    "\n",
    "    #zero means that user has never voted for this item.\n",
    "    rating_matrix = new_ratings.pivot(index='userId',columns='eventId',values='rating').fillna(0)\n",
    "    \n",
    "#     print(rating_matrix)\n",
    "    knn = NearestNeighbors(metric='cosine',algorithm='brute')\n",
    "    knn.fit((rating_matrix.to_numpy()))\n",
    "\n",
    "    userid = input_user_id\n",
    "\n",
    "    similar_user =[]\n",
    "\n",
    "    # (excluded itself)\n",
    "    value = rating_matrix.loc[ userid,:].values\n",
    "    value = value.reshape(1,-1)\n",
    "    print(rating_matrix.shape,'=====',np.shape(value))\n",
    "    distances, indices = knn.kneighbors(value,n_neighbors=n) \n",
    "    distances=distances.flatten()\n",
    "    indices=indices.flatten()\n",
    "\n",
    "    print(\"Five Nearest Neighbors of user{0}:\".format(userid))\n",
    "\n",
    "    for i in range(1,len(distances)):\n",
    "        similar_user.append(rating_matrix.index[indices[i]])\n",
    "    print('about to return! ',similar_user)\n",
    "    return similar_user\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_user_id=414\n",
    "min_active=1000000\n",
    "rec=100\n",
    "\n",
    "#get data\n",
    "data,df_events,df_rating,df_old_events,df_new_events=get_prep_data(input_user_id)\n",
    "#main function\n",
    "def system(input_user_id,df_new_events, df_old_events,df_rating,min_active_users=min_active,recent=rec):\n",
    "    app_active_users = []\n",
    "    \n",
    "    for n_e in range(len(df_new_events)):\n",
    "        if df_new_events.iloc[n_e]['eventId'] in df_rating['eventId']:\n",
    "            app_active_users.extend( list(df_rating[df_rating['eventId'] == df_new_events.iloc[n_e]['eventId'] ]['userId'])  )\n",
    "    app_active_users=np.unique(np.array(app_active_users))\n",
    "    #Post cold start        \n",
    "    similar_users_id=[]\n",
    "    if len(app_active_users)> min_active_users:\n",
    "        app_active_users=np.append(app_active_users,input_user_id)\n",
    "\n",
    "        df_subset_ratings = df_rating[df_rating.userId.isin(app_active_users)]\n",
    "\n",
    "        similar_users_id = get_similar_users(input_user_id,df_subset_ratings, df_old_events)\n",
    "        similar_users_id.append(input_user_id)\n",
    "        \n",
    "        #get older user data.\n",
    "        df_user_rating = df_rating[df_rating['userId']==input_user_id]\n",
    "\n",
    "        recentRatings=df_user_rating.sort_values('timestamp')['eventId'].unique()[:recent]\n",
    "        df_ratings_old=df_rating.loc[df_rating['eventId'].isin(recentRatings)]\n",
    "\n",
    "        #similar users\n",
    "        df_ratings_old=df_ratings_old.loc[df_ratings_old['userId'].isin(similar_users_id)]\n",
    "        df_ratings_new=df_rating.loc[df_rating['eventId'].isin(list(df_new_events['eventId']))]\n",
    "\n",
    "        #get Recommended Events...\n",
    "        df_ratings_new=df_ratings_new.loc[df_ratings_new['userId'].isin(similar_users_id)]\n",
    "        df_ratings_new\n",
    "        \n",
    "        df_all=df_ratings_new.append(df_ratings_old,ignore_index=True)\n",
    "        df_pivot=df_all.pivot(index='userId',columns='eventId',values='rating').fillna(0)\n",
    "        df_pivot\n",
    "\n",
    "        R = df_pivot.to_numpy()\n",
    "        mean_ =(np.mean(R, axis = 1)).reshape(-1, 1)\n",
    "\n",
    "        U, sigma, E = svds(R - mean_, k = 5)\n",
    "        sigma = np.diag(sigma)\n",
    "\n",
    "        dot_prod =np.dot(np.dot(U, sigma),E)\n",
    "        ratings_pred = dot_prod  + mean_\n",
    "\n",
    "        preds_matrix = pd.DataFrame(ratings_pred, columns = df_pivot.columns,index=df_pivot.index)\n",
    "        # predictions = recommend_eventss(input_user_id ,preds_matrix, df_new_events, df_pivot)\n",
    "\n",
    "        # return predictions\n",
    "        preds_matrix\n",
    "\n",
    "        # user_predictions = preds_matrix.loc[userID]\n",
    "        events_pred=preds_matrix.loc[input_user_id].sort_values(ascending=False)[:10].index.to_list()\n",
    "\n",
    "        return events_pred\n",
    "    \n",
    "    else:\n",
    "        #Check inputs again to be sure they contain the user\n",
    "        userRated=df_rating.loc[df_rating['userId']==input_user_id]\n",
    "        df_old_events=df_old_events.loc[df_old_events['eventId'].isin(list(userRated['eventId']))]\n",
    "        \n",
    "        #new(without user rating) + old events(with user ratings)\n",
    "        result=df_old_events.append(df_new_events,ignore_index=True) #get old to new.\n",
    "\n",
    "        description = result['Description'] # Description of all\n",
    "        tf = TfidfVectorizer(analyzer='word',ngram_range=(1, 3),min_df=0, stop_words='english')\n",
    "        tfidf = tf.fit_transform(description)\n",
    "\n",
    "        cosine_similarity = linear_kernel(tfidf, tfidf)\n",
    "\n",
    "        df_cosine_sim=pd.DataFrame(data=cosine_similarity,columns=result['eventId'],index=result['eventId'])\n",
    "\n",
    "        # old ratings -> recent=100 by default and min rating>=4\n",
    "        \n",
    "        min_rating=4\n",
    "        \n",
    "        recent_events=df_old_events.merge(df_rating,on='eventId')\n",
    "        recent_events=recent_events.loc[recent_events['rating']>=min_rating].sort_values(by='timestamp',ascending=False)['eventId'][:recent]\n",
    "        \n",
    "        #get df slice with predicted values\n",
    "        pred=df_cosine_sim.loc[df_cosine_sim.index.isin(recent_events),list(df_new_events['eventId'])]\n",
    "        \n",
    "        #get top 10 predictions based on max! 0th index=>Most recommended =>9th index=>10th place on recommendation\n",
    "        predictions=pred.max().sort_values(ascending=False).index[:10].to_list()\n",
    "        print(predictions)\n",
    "        \n",
    "        return predictions\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[232, 38, 82, 275, 320, 330, 271, 287, 306, 302]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[232, 38, 82, 275, 320, 330, 271, 287, 306, 302]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system(input_user_id,df_new_events, df_old_events,df_rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:recommender_env] *",
   "language": "python",
   "name": "conda-env-recommender_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
